{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phuongnm/SP_LLMs/env_llm/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "from main import *\n",
    "import yaml\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import json\n",
    "import random\n",
    "import argparse\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from transformers import LlamaTokenizer, LlamaForSequenceClassification\n",
    "import torch, sys\n",
    "from tqdm import tqdm\n",
    "from transformers import LlamaTokenizer, AutoModel, AutoTokenizer\n",
    "            \n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n",
      "Loading checkpoint shards: 100%|██████████| 15/15 [00:22<00:00,  1.51s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 8192, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-79): 80 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear8bitLt(in_features=8192, out_features=8192, bias=False)\n",
       "          (k_proj): Linear8bitLt(in_features=8192, out_features=1024, bias=False)\n",
       "          (v_proj): Linear8bitLt(in_features=8192, out_features=1024, bias=False)\n",
       "          (o_proj): Linear8bitLt(in_features=8192, out_features=8192, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=8192, out_features=28672, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=8192, out_features=28672, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=28672, out_features=8192, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=8192, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import LlamaTokenizer, AutoModel, AutoTokenizer,LlamaForCausalLM\n",
    "model_name = 'meta-llama/Llama-2-70b-chat-hf'\n",
    "print(\"Loading model ...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name) \n",
    "model = LlamaForCausalLM.from_pretrained(model_name, device_map=\"auto\", load_in_8bit=True)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class BatchPreprocessorLLM(BatchPreprocessor): \n",
    "    def __init__(self, tokenizer, dataset_name=None, window_ct=2, emotion_labels=[]) -> None:\n",
    "        self.tokenizer = tokenizer\n",
    "        self.separate_token_id = self.tokenizer.convert_tokens_to_ids(\"</s>\")\n",
    "        self.dataset_name  = dataset_name\n",
    "        self.window_ct = window_ct\n",
    "        self.emotion_labels = emotion_labels\n",
    "        self.printted = False\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_raw_data(path_data):\n",
    "        raw_data = json.load(open(path_data))\n",
    "        if isinstance(raw_data, dict):\n",
    "            new_data_list = []\n",
    "            for k, v in raw_data.items():\n",
    "                v['s_id'] = k\n",
    "                new_data_list.append(v)\n",
    "            return new_data_list\n",
    "        elif isinstance(raw_data, list):\n",
    "            return raw_data\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_speaker_name(s_id, gender, data_name):\n",
    "        if data_name == \"iemocap\":\n",
    "            # iemocap: label index mapping = {'hap':0, 'sad':1, 'neu':2, 'ang':3, 'exc':4, 'fru':5}\n",
    "            speaker = {\n",
    "                        \"Ses01\": {\"F\": \"Mary\", \"M\": \"James\"},\n",
    "                        \"Ses02\": {\"F\": \"Patricia\", \"M\": \"John\"},\n",
    "                        \"Ses03\": {\"F\": \"Jennifer\", \"M\": \"Robert\"},\n",
    "                        \"Ses04\": {\"F\": \"Linda\", \"M\": \"Michael\"},\n",
    "                        \"Ses05\": {\"F\": \"Elizabeth\", \"M\": \"William\"},\n",
    "                    }\n",
    "            s_id_first_part = s_id[:5]\n",
    "            return speaker[s_id_first_part][gender].upper()\n",
    "        elif data_name in ['meld', \"emorynlp\"]:\n",
    "            # emorynlp: label index mapping =  {'Joyful': 0, 'Mad': 1, 'Peaceful': 2, 'Neutral': 3, 'Sad': 4, 'Powerful': 5, 'Scared': 6}\n",
    "            # meld: label index mapping = {'neutral': 0, 'surprise': 1, 'fear': 2, 'sadness': 3, 'joy': 4, 'disgust': 5, 'anger':6}\n",
    "            gender_idx = gender.index(1) \n",
    "            return f\"SPEAKER_{gender_idx}\"\n",
    "        elif data_name=='dailydialog':\n",
    "            # dailydialog:  {'no_emotion': 0, 'happiness': 1, 'sadness': 2, 'surprise': 3,  'anger': 4, 'fear': 5, 'disgust':6}\n",
    "            return f\"SPEAKER_{gender}\"\n",
    "        \n",
    "    def sentence_mixed_by_surrounding(self, sentences, around_window, s_id, genders, data_name):\n",
    "        new_conversations = []\n",
    "        align_sents = []\n",
    "        for i, cur_sent in enumerate(sentences):\n",
    "            tmp_s = \"\"\n",
    "            for j in range(max(0, i-around_window), min(len(sentences), i+around_window+1)):\n",
    "                u_j =  f\"{self.get_speaker_name(s_id, genders[j], data_name=data_name)}: {sentences[j]}\"\n",
    "                if i == j:\n",
    "                    align_sents.append(u_j)\n",
    "                tmp_s +=  f\"\\n{u_j}\"\n",
    "            new_conversations.append(tmp_s)\n",
    "        return new_conversations, align_sents\n",
    "    \n",
    "    def __call__(self, batch):\n",
    "        raw_sentences = []\n",
    "        raw_sentences_flatten = []\n",
    "        labels = []\n",
    "        speaker_info = []\n",
    "        listener_info = []\n",
    "\n",
    "        # masked tensor  \n",
    "        lengths = [len(sample['sentences']) for sample in batch]\n",
    "        max_len_conversation = max(lengths)\n",
    "        padding_utterance_masked = torch.BoolTensor([[False]*l_i+ [True]*(max_len_conversation - l_i) for l_i in lengths])\n",
    "\n",
    "        # collect all sentences\n",
    "        # - intra speaker\n",
    "        flatten_data = []\n",
    "        intra_speaker_masekd_all = torch.BoolTensor(len(batch), max_len_conversation,max_len_conversation)\n",
    "        for i, sample in enumerate(batch):\n",
    "            new_conversations, align_sents = self.sentence_mixed_by_surrounding(sample['sentences'], \n",
    "                                                                        around_window=self.window_ct, \n",
    "                                                                        s_id=sample['s_id'], \n",
    "                                                                        genders=sample['genders'],\n",
    "                                                                        data_name=self.dataset_name)\n",
    "            few_shot_example = \"\"\"\\n=======\n",
    "Context: Given predefined emotional label set [happy, sad, neutral, angry, excited, frustrated], and bellow conversation: \n",
    "\"\n",
    "PATRICIA: You know, it's lovely here, the air is sweet.\n",
    "PATRICIA: No, not sorry.  But, um. But I'm not gonna stay.\n",
    "JOHN: The trouble is, I planned on sort of sneaking up on you on a period of a week or so.  But they take it for granted that we're all set.\n",
    "PATRICIA: I knew they would, your mother anyway.\n",
    "PATRICIA: Well, from her point of view, why else would I come?\n",
    "PATRICIA: I guess this is why I came.\n",
    "JOHN: I'm embarrassing you and I didn't want to tell it to you here.  I wanted some place we'd never been before.  A place where we'd be brand new to each other.\n",
    "PATRICIA: Well, you started to write me\n",
    "JOHN: You felt something that far back?\n",
    "PATRICIA: Every day since.\n",
    "JOHN: Ann, why didn't you let me know?\n",
    "JOHN: Let's drive someplace.  I want to be alone with you.\n",
    "JOHN: No.  Nothing like that.\n",
    "\"\n",
    "\n",
    "Question: What is the emotion of the speaker at the utterance \"PATRICIA: Well, from her point of view, why else would I come?\"?\n",
    "Answer: neutral\n",
    "\n",
    "Question: What is the emotion of the speaker at the utterance \"PATRICIA: I guess this is why I came.\"?\n",
    "Answer: happy\n",
    "\n",
    "Question: What is the emotion of the speaker at the utterance \"JOHN: I'm embarrassing you and I didn't want to tell it to you here.  I wanted some place we'd never been before.  A place where we'd be brand new to each other.\"?\n",
    "Answer: excited\n",
    "\"\"\"\n",
    "            for i_u, (conv, utterance) in enumerate(zip(new_conversations, align_sents)):\n",
    "                prompt_extract_context_vect = few_shot_example + f\"\\n=======\\nContext: Given predefined emotional label set [{', '.join(self.emotion_labels)}], and bellow conversation:\\n\\\"{conv}\\n\\\"\\n\\nQuestion: What is the emotion of the speaker at the utterance \\\"{utterance}\\\"?\\nAnswer:\" \n",
    "                if not self.printted:\n",
    "                    print(prompt_extract_context_vect)\n",
    "                    self.printted = True \n",
    "                    \n",
    "                inputs = self.tokenizer(prompt_extract_context_vect, return_tensors=\"pt\")\n",
    "                input_ids = inputs[\"input_ids\"] \n",
    "                flatten_data.append({\n",
    "                    \"s_id\": sample['s_id'],\n",
    "                    \"u_idx\": i_u,\n",
    "                    \"prompt_content\": prompt_extract_context_vect,\n",
    "                    \"input_ids\": input_ids,\n",
    "                    }\n",
    "                )\n",
    "                \n",
    "        return flatten_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BatchPreprocessorLLMSpeakerDescription(BatchPreprocessor): \n",
    "    def __init__(self, tokenizer, dataset_name=None, window_ct=2, emotion_labels=[]) -> None:\n",
    "        self.tokenizer = tokenizer\n",
    "        self.separate_token_id = self.tokenizer.convert_tokens_to_ids(\"</s>\")\n",
    "        self.dataset_name  = dataset_name\n",
    "        self.window_ct = window_ct\n",
    "        self.emotion_labels = emotion_labels\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_raw_data(path_data):\n",
    "        raw_data = json.load(open(path_data))\n",
    "        if isinstance(raw_data, dict):\n",
    "            new_data_list = []\n",
    "            for k, v in raw_data.items():\n",
    "                v['s_id'] = k\n",
    "                new_data_list.append(v)\n",
    "            return new_data_list\n",
    "        elif isinstance(raw_data, list):\n",
    "            return raw_data\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_speaker_name(s_id, gender, data_name):\n",
    "        if data_name == \"iemocap\":\n",
    "            # iemocap: label index mapping = {'hap':0, 'sad':1, 'neu':2, 'ang':3, 'exc':4, 'fru':5}\n",
    "            speaker = {\n",
    "                        \"Ses01\": {\"F\": \"Mary\", \"M\": \"James\"},\n",
    "                        \"Ses02\": {\"F\": \"Patricia\", \"M\": \"John\"},\n",
    "                        \"Ses03\": {\"F\": \"Jennifer\", \"M\": \"Robert\"},\n",
    "                        \"Ses04\": {\"F\": \"Linda\", \"M\": \"Michael\"},\n",
    "                        \"Ses05\": {\"F\": \"Elizabeth\", \"M\": \"William\"},\n",
    "                    }\n",
    "            s_id_first_part = s_id[:5]\n",
    "            return speaker[s_id_first_part][gender].upper()\n",
    "        elif data_name in ['meld', \"emorynlp\"]:\n",
    "            # emorynlp: label index mapping =  {'Joyful': 0, 'Mad': 1, 'Peaceful': 2, 'Neutral': 3, 'Sad': 4, 'Powerful': 5, 'Scared': 6}\n",
    "            # meld: label index mapping = {'neutral': 0, 'surprise': 1, 'fear': 2, 'sadness': 3, 'joy': 4, 'disgust': 5, 'anger':6}\n",
    "            gender_idx = gender.index(1) \n",
    "            return f\"SPEAKER_{gender_idx}\"\n",
    "        elif data_name=='dailydialog':\n",
    "            # dailydialog:  {'no_emotion': 0, 'happiness': 1, 'sadness': 2, 'surprise': 3,  'anger': 4, 'fear': 5, 'disgust':6}\n",
    "            return f\"SPEAKER_{gender}\"\n",
    "    \n",
    "    def __call__(self, batch):\n",
    "        raw_sentences = []\n",
    "        raw_sentences_flatten = []\n",
    "        labels = []\n",
    "        speaker_info = []\n",
    "        listener_info = []\n",
    "\n",
    "        # masked tensor  \n",
    "        lengths = [len(sample['sentences']) for sample in batch]\n",
    "        max_len_conversation = max(lengths)\n",
    "        padding_utterance_masked = torch.BoolTensor([[False]*l_i+ [True]*(max_len_conversation - l_i) for l_i in lengths])\n",
    "\n",
    "        # collect all sentences\n",
    "        # - intra speaker\n",
    "        new_data = []\n",
    "        intra_speaker_masekd_all = torch.BoolTensor(len(batch), max_len_conversation,max_len_conversation)\n",
    "        for i, sample in enumerate(batch):\n",
    "\n",
    "            all_utterances = []\n",
    "            all_speaker_names= []\n",
    "            for i_u, u in enumerate(sample['sentences']):\n",
    "                speaker_name = self.get_speaker_name(sample['s_id'], sample['genders'][i_u], self.dataset_name)\n",
    "                u_full_name = f'{speaker_name}: {u}'\n",
    "                all_utterances.append(u_full_name)\n",
    "                all_speaker_names.append(speaker_name) \n",
    "            \n",
    "            full_conversation = \"\\n\".join(all_utterances)\n",
    "            prompts_speaker_description_word_ids = {}\n",
    "            prompting_input = {}\n",
    "            for speaker_name in set(all_speaker_names):\n",
    "                prompting =\"Given this conversation between speakers: \\n\\\"\" + full_conversation + \"\\n\\\"\\nIn overall of above conversation, what do you think about the characteristics speaker {}? (Note: provide an answer within 250 words)\".format(speaker_name) \n",
    "                prompts_speaker_description_word_ids[speaker_name] = self.tokenizer(prompting, return_tensors=\"pt\")[\"input_ids\"]\n",
    "                prompting_input[speaker_name] = prompting\n",
    "                \n",
    "            new_data.append({\n",
    "                    \"s_id\": sample['s_id'],\n",
    "                    'sentences': all_utterances,\n",
    "                    \"prompting_input\": prompting_input,\n",
    "                    \"speaker_names\": all_speaker_names,\n",
    "                    \"prompts_speaker_description_word_ids\": prompts_speaker_description_word_ids\n",
    "                    }\n",
    "                )\n",
    "                \n",
    "        return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [41:53<00:00, 209.47s/it]\n",
      "100%|██████████| 108/108 [6:10:00<00:00, 205.56s/it] \n",
      "100%|██████████| 31/31 [1:45:58<00:00, 205.12s/it]\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "\n",
    "dataset_name = 'iemocap'\n",
    "data_folder = '/home/phuongnm/per_erc/data/'\n",
    "\n",
    "\n",
    "for type_data in ['valid',  'train', 'test']:\n",
    "    data_name_pattern= f'{dataset_name}.{type_data}'\n",
    "    \n",
    "    \n",
    "    raw_data = BatchPreprocessor.load_raw_data(f\"{data_folder}/{data_name_pattern}.json\")\n",
    "    \n",
    "    data_preprocessor = BatchPreprocessorLLMSpeakerDescription(tokenizer, dataset_name=dataset_name, window_ct=4, \n",
    "                                             emotion_labels=['happy', 'sad', 'neutral', 'angry', 'excited', 'frustrated'])\n",
    "    all_data = {}\n",
    "    test_loader = DataLoader(raw_data, \n",
    "                             batch_size=1, \n",
    "                             collate_fn=data_preprocessor, \n",
    "                             shuffle=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, convs in enumerate(tqdm(test_loader)):\n",
    "            for j, conv in enumerate(convs):\n",
    "                speaker_descriptions = []\n",
    "                map_speaker2descriptions = {}\n",
    "\n",
    "                for speaker_name, prompt_speaker_des_ids in conv['prompts_speaker_description_word_ids'].items():\n",
    "                    input_ids = prompt_speaker_des_ids.to(\"cuda\") \n",
    "                    outputs = model.generate(input_ids, max_new_tokens=300)\n",
    "                    map_speaker2descriptions[speaker_name] = tokenizer.decode(outputs[0])\n",
    "\n",
    "                for sp_name in conv['speaker_names']:\n",
    "                    speaker_descriptions.append(map_speaker2descriptions[sp_name].replace(conv['prompting_input'][sp_name], ''))\n",
    "            \n",
    "                all_data[conv['s_id']] = speaker_descriptions\n",
    "            json.dump(all_data, open(f'{data_folder}/llm_vectors/{data_name_pattern}_speaker_descriptions.json', 'wt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# dataset_name = 'iemocap'\n",
    "# data_folder = '/home/phuongnm/per_erc/data/'\n",
    "\n",
    "\n",
    "# for type_data in [ 'train', 'valid', 'test']:\n",
    "#     data_name_pattern= f'{dataset_name}.{type_data}'\n",
    "    \n",
    "    \n",
    "#     raw_data = BatchPreprocessor.load_raw_data(f\"{data_folder}/{data_name_pattern}.json\")\n",
    "    \n",
    "#     data_preprocessor = BatchPreprocessorLLM(tokenizer, dataset_name=dataset_name, window_ct=4, \n",
    "#                                              emotion_labels=['happy', 'sad', 'neutral', 'angry', 'excited', 'frustrated'])\n",
    "#     all_data = {}\n",
    "    \n",
    "#     test_loader = DataLoader(raw_data, \n",
    "#                              batch_size=1, \n",
    "#                              collate_fn=data_preprocessor, \n",
    "#                              shuffle=False)\n",
    "#     with torch.no_grad():\n",
    "#         for i, conv in enumerate(tqdm(test_loader)):\n",
    "#             llm_vectors = []\n",
    "#             for i_s, sent in enumerate(conv):\n",
    "#                 input_ids = sent['input_ids'].to(\"cuda\")\n",
    "#                 outputs = model(input_ids)\n",
    "#                 sent.pop('input_ids')\n",
    "#                 llm_vectors.append(outputs.last_hidden_state[0][0].cpu())\n",
    "        \n",
    "#             all_data[conv[0]['s_id']] = llm_vectors\n",
    "#     pickle.dump(all_data, open(f'{data_folder}/llm_vectors/{data_name_pattern}_llm_fewshot.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "c6a2877e1bfde4f5f029020970de5fe9d6d098c79260600128974293316b861d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
