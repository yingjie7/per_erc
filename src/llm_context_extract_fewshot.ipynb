{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phuongnm/SP_LLMs/env_llm/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "from main import *\n",
    "import yaml\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import json\n",
    "import random\n",
    "import argparse\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from transformers import LlamaTokenizer, LlamaForSequenceClassification\n",
    "import torch, sys\n",
    "from tqdm import tqdm\n",
    "from transformers import LlamaTokenizer, AutoModel, AutoTokenizer\n",
    "            \n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n",
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n",
      "Loading checkpoint shards: 100%|██████████| 7/7 [02:11<00:00, 18.77s/it]\n",
      "Downloading (…)neration_config.json: 100%|██████████| 132/132 [00:00<00:00, 12.9kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 6656, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-59): 60 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear8bitLt(in_features=6656, out_features=6656, bias=False)\n",
       "          (k_proj): Linear8bitLt(in_features=6656, out_features=6656, bias=False)\n",
       "          (v_proj): Linear8bitLt(in_features=6656, out_features=6656, bias=False)\n",
       "          (o_proj): Linear8bitLt(in_features=6656, out_features=6656, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=6656, out_features=17920, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=6656, out_features=17920, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=17920, out_features=6656, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=6656, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import  AutoModel, AutoTokenizer,AutoModelForCausalLM\n",
    "model_name = 'lmsys/vicuna-33b-v1.3'\n",
    "print(\"Loading model ...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name) \n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", load_in_8bit=True)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class BatchPreprocessorLLM(BatchPreprocessor): \n",
    "    def __init__(self, tokenizer, dataset_name=None, window_ct=2, emotion_labels=[]) -> None:\n",
    "        self.tokenizer = tokenizer\n",
    "        self.separate_token_id = self.tokenizer.convert_tokens_to_ids(\"</s>\")\n",
    "        self.dataset_name  = dataset_name\n",
    "        self.window_ct = window_ct\n",
    "        self.emotion_labels = emotion_labels\n",
    "        self.printted = False\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_raw_data(path_data):\n",
    "        raw_data = json.load(open(path_data))\n",
    "        if isinstance(raw_data, dict):\n",
    "            new_data_list = []\n",
    "            for k, v in raw_data.items():\n",
    "                v['s_id'] = k\n",
    "                new_data_list.append(v)\n",
    "            return new_data_list\n",
    "        elif isinstance(raw_data, list):\n",
    "            return raw_data\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_speaker_name(s_id, gender, data_name):\n",
    "        if data_name == \"iemocap\":\n",
    "            # iemocap: label index mapping = {'hap':0, 'sad':1, 'neu':2, 'ang':3, 'exc':4, 'fru':5}\n",
    "            speaker = {\n",
    "                        \"Ses01\": {\"F\": \"Mary\", \"M\": \"James\"},\n",
    "                        \"Ses02\": {\"F\": \"Patricia\", \"M\": \"John\"},\n",
    "                        \"Ses03\": {\"F\": \"Jennifer\", \"M\": \"Robert\"},\n",
    "                        \"Ses04\": {\"F\": \"Linda\", \"M\": \"Michael\"},\n",
    "                        \"Ses05\": {\"F\": \"Elizabeth\", \"M\": \"William\"},\n",
    "                    }\n",
    "            s_id_first_part = s_id[:5]\n",
    "            return speaker[s_id_first_part][gender].upper()\n",
    "        elif data_name in ['meld', \"emorynlp\"]:\n",
    "            # emorynlp: label index mapping =  {'Joyful': 0, 'Mad': 1, 'Peaceful': 2, 'Neutral': 3, 'Sad': 4, 'Powerful': 5, 'Scared': 6}\n",
    "            # meld: label index mapping = {'neutral': 0, 'surprise': 1, 'fear': 2, 'sadness': 3, 'joy': 4, 'disgust': 5, 'anger':6}\n",
    "            gender_idx = gender.index(1) \n",
    "            return f\"SPEAKER_{gender_idx}\"\n",
    "        elif data_name=='dailydialog':\n",
    "            # dailydialog:  {'no_emotion': 0, 'happiness': 1, 'sadness': 2, 'surprise': 3,  'anger': 4, 'fear': 5, 'disgust':6}\n",
    "            return f\"SPEAKER_{gender}\"\n",
    "        \n",
    "    def sentence_mixed_by_surrounding(self, sentences, around_window, s_id, genders, data_name):\n",
    "        new_conversations = []\n",
    "        align_sents = []\n",
    "        for i, cur_sent in enumerate(sentences):\n",
    "            tmp_s = \"\"\n",
    "            for j in range(max(0, i-around_window), min(len(sentences), i+around_window+1)):\n",
    "                u_j =  f\"{self.get_speaker_name(s_id, genders[j], data_name=data_name)}: {sentences[j]}\"\n",
    "                if i == j:\n",
    "                    align_sents.append(u_j)\n",
    "                tmp_s +=  f\"\\n{u_j}\"\n",
    "            new_conversations.append(tmp_s)\n",
    "        return new_conversations, align_sents\n",
    "    \n",
    "    def __call__(self, batch):\n",
    "        raw_sentences = []\n",
    "        raw_sentences_flatten = []\n",
    "        labels = []\n",
    "        speaker_info = []\n",
    "        listener_info = []\n",
    "\n",
    "        # masked tensor  \n",
    "        lengths = [len(sample['sentences']) for sample in batch]\n",
    "        max_len_conversation = max(lengths)\n",
    "        padding_utterance_masked = torch.BoolTensor([[False]*l_i+ [True]*(max_len_conversation - l_i) for l_i in lengths])\n",
    "\n",
    "        # collect all sentences\n",
    "        # - intra speaker\n",
    "        flatten_data = []\n",
    "        intra_speaker_masekd_all = torch.BoolTensor(len(batch), max_len_conversation,max_len_conversation)\n",
    "        for i, sample in enumerate(batch):\n",
    "            new_conversations, align_sents = self.sentence_mixed_by_surrounding(sample['sentences'], \n",
    "                                                                        around_window=self.window_ct, \n",
    "                                                                        s_id=sample['s_id'], \n",
    "                                                                        genders=sample['genders'],\n",
    "                                                                        data_name=self.dataset_name)\n",
    "            few_shot_example = \"\"\"\\n=======\n",
    "Context: Given predefined emotional label set [happy, sad, neutral, angry, excited, frustrated], and bellow conversation: \n",
    "\"\n",
    "PATRICIA: You know, it's lovely here, the air is sweet.\n",
    "PATRICIA: No, not sorry.  But, um. But I'm not gonna stay.\n",
    "JOHN: The trouble is, I planned on sort of sneaking up on you on a period of a week or so.  But they take it for granted that we're all set.\n",
    "PATRICIA: I knew they would, your mother anyway.\n",
    "PATRICIA: Well, from her point of view, why else would I come?\n",
    "PATRICIA: I guess this is why I came.\n",
    "JOHN: I'm embarrassing you and I didn't want to tell it to you here.  I wanted some place we'd never been before.  A place where we'd be brand new to each other.\n",
    "PATRICIA: Well, you started to write me\n",
    "JOHN: You felt something that far back?\n",
    "PATRICIA: Every day since.\n",
    "JOHN: Ann, why didn't you let me know?\n",
    "JOHN: Let's drive someplace.  I want to be alone with you.\n",
    "JOHN: No.  Nothing like that.\n",
    "\"\n",
    "\n",
    "Question: What is the emotion of the speaker at the utterance \"PATRICIA: Well, from her point of view, why else would I come?\"?\n",
    "Answer: neutral\n",
    "\n",
    "Question: What is the emotion of the speaker at the utterance \"PATRICIA: I guess this is why I came.\"?\n",
    "Answer: happy\n",
    "\n",
    "Question: What is the emotion of the speaker at the utterance \"JOHN: I'm embarrassing you and I didn't want to tell it to you here.  I wanted some place we'd never been before.  A place where we'd be brand new to each other.\"?\n",
    "Answer: excited\n",
    "\"\"\"\n",
    "            for i_u, (conv, utterance) in enumerate(zip(new_conversations, align_sents)):\n",
    "                prompt_extract_context_vect = few_shot_example + f\"\\n=======\\nContext: Given predefined emotional label set [{', '.join(self.emotion_labels)}], and bellow conversation:\\n\\\"{conv}\\n\\\"\\n\\nQuestion: What is the emotion of the speaker at the utterance \\\"{utterance}\\\"?\\nAnswer:\" \n",
    "                if not self.printted:\n",
    "                    print(prompt_extract_context_vect)\n",
    "                    self.printted = True \n",
    "                    \n",
    "                inputs = self.tokenizer(prompt_extract_context_vect, return_tensors=\"pt\")\n",
    "                input_ids = inputs[\"input_ids\"] \n",
    "                flatten_data.append({\n",
    "                    \"s_id\": sample['s_id'],\n",
    "                    \"u_idx\": i_u,\n",
    "                    \"prompt_content\": prompt_extract_context_vect,\n",
    "                    \"input_ids\": input_ids,\n",
    "                    }\n",
    "                )\n",
    "                \n",
    "        return flatten_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BatchPreprocessorLLMSpeakerDescription(BatchPreprocessor): \n",
    "    def __init__(self, tokenizer, dataset_name=None, window_ct=2, emotion_labels=[]) -> None:\n",
    "        self.tokenizer = tokenizer\n",
    "        self.separate_token_id = self.tokenizer.convert_tokens_to_ids(\"</s>\")\n",
    "        self.dataset_name  = dataset_name\n",
    "        self.window_ct = window_ct\n",
    "        self.emotion_labels = emotion_labels\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_raw_data(path_data):\n",
    "        raw_data = json.load(open(path_data))\n",
    "        if isinstance(raw_data, dict):\n",
    "            new_data_list = []\n",
    "            for k, v in raw_data.items():\n",
    "                v['s_id'] = k\n",
    "                new_data_list.append(v)\n",
    "            return new_data_list\n",
    "        elif isinstance(raw_data, list):\n",
    "            return raw_data\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_speaker_name(s_id, gender, data_name):\n",
    "        if data_name == \"iemocap\":\n",
    "            # iemocap: label index mapping = {'hap':0, 'sad':1, 'neu':2, 'ang':3, 'exc':4, 'fru':5}\n",
    "            speaker = {\n",
    "                        \"Ses01\": {\"F\": \"Mary\", \"M\": \"James\"},\n",
    "                        \"Ses02\": {\"F\": \"Patricia\", \"M\": \"John\"},\n",
    "                        \"Ses03\": {\"F\": \"Jennifer\", \"M\": \"Robert\"},\n",
    "                        \"Ses04\": {\"F\": \"Linda\", \"M\": \"Michael\"},\n",
    "                        \"Ses05\": {\"F\": \"Elizabeth\", \"M\": \"William\"},\n",
    "                    }\n",
    "            s_id_first_part = s_id[:5]\n",
    "            return speaker[s_id_first_part][gender].upper()\n",
    "        elif data_name in ['meld', \"emorynlp\"]:\n",
    "            # emorynlp: label index mapping =  {'Joyful': 0, 'Mad': 1, 'Peaceful': 2, 'Neutral': 3, 'Sad': 4, 'Powerful': 5, 'Scared': 6}\n",
    "            # meld: label index mapping = {'neutral': 0, 'surprise': 1, 'fear': 2, 'sadness': 3, 'joy': 4, 'disgust': 5, 'anger':6}\n",
    "            gender_idx = gender.index(1) \n",
    "            return f\"SPEAKER_{gender_idx}\"\n",
    "        elif data_name=='dailydialog':\n",
    "            # dailydialog:  {'no_emotion': 0, 'happiness': 1, 'sadness': 2, 'surprise': 3,  'anger': 4, 'fear': 5, 'disgust':6}\n",
    "            return f\"SPEAKER_{gender}\"\n",
    "        \n",
    "    def preprocess(self, all_conversations):\n",
    "        \n",
    "        new_data = {}\n",
    "        gr_by_len = {}\n",
    "        for i, sample in enumerate(all_conversations):\n",
    "\n",
    "            all_utterances = []\n",
    "            all_speaker_names= []\n",
    "            for i_u, u in enumerate(sample['sentences']):\n",
    "                speaker_name = self.get_speaker_name(sample['s_id'], sample['genders'][i_u], self.dataset_name)\n",
    "                u_full_name = f'{speaker_name}: {u}'\n",
    "                all_utterances.append(u_full_name)\n",
    "                all_speaker_names.append(speaker_name) \n",
    "            \n",
    "            full_conversation = \"\\n\".join(all_utterances)\n",
    "            prompts_speaker_description_word_ids = {}\n",
    "            prompting_input = {}\n",
    "            for speaker_name in set(all_speaker_names):\n",
    "                prompting =\"Given this conversation between speakers: \\n\\\"\" + full_conversation + \"\\n\\\"\\nIn overall of above conversation, what do you think about the characteristics speaker {}? (Note: provide an answer within 250 words)\".format(speaker_name) \n",
    "                prompts_speaker_description_word_ids[speaker_name] = self.tokenizer(prompting, return_tensors=\"pt\")[\"input_ids\"]\n",
    "                prompting_input[speaker_name] = prompting\n",
    "                \n",
    "                # group by len for batch decode by llm \n",
    "                if prompts_speaker_description_word_ids[speaker_name].shape[-1] not in  gr_by_len:\n",
    "                    gr_by_len[prompts_speaker_description_word_ids[speaker_name].shape[-1]] = []\n",
    "                gr_by_len[prompts_speaker_description_word_ids[speaker_name].shape[-1]].append({\n",
    "                    'w_ids': prompts_speaker_description_word_ids[speaker_name],\n",
    "                    'conv_id': sample['s_id'],\n",
    "                    'type_data': sample['type_data'],\n",
    "                    \"prompting_input\": prompting,\n",
    "                    'speaker_name': speaker_name,\n",
    "                    'all_speaker_names': all_speaker_names\n",
    "                })\n",
    "                \n",
    "        return gr_by_len\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Continue process 114 conversations in data-type =valid\n",
      "- Continue process 280 conversations in data-type =test\n",
      "- Continue process 1038 conversations in data-type =train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/441 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import json \n",
    "import os \n",
    "import traceback\n",
    "\n",
    "dataset_name = 'meld'\n",
    "data_folder = '../data/'\n",
    "\n",
    "raw_data = []\n",
    "for type_data in ['valid', 'test', 'train']:\n",
    "    data_name_pattern= f'{dataset_name}.{type_data}'\n",
    "    path_processed_data = f'{data_folder}/llm_vectors/{data_name_pattern}_spdesc_{model_name.split(\"/\")[-1]}.json'\n",
    "    \n",
    "    org_raw_data = BatchPreprocessorLLMSpeakerDescription.load_raw_data(f\"{data_folder}/{data_name_pattern}.json\")\n",
    "    \n",
    "    if os.path.exists(path_processed_data):\n",
    "        processed_data = json.load(open(path_processed_data, 'rt'))\n",
    "        print(f'- sucessful processed {len(processed_data)}/{len(org_raw_data)} conversations in data-type ={type_data}')\n",
    "        json.dump(processed_data, open(path_processed_data+\"_backup.json\", 'wt'), indent=2)\n",
    "        org_raw_data = [e for e in org_raw_data if e['s_id'] not in processed_data]\n",
    "        \n",
    "    print(f'- Continue process {len(org_raw_data)} conversations in data-type ={type_data}')\n",
    "    for e in org_raw_data:\n",
    "        e['type_data'] = type_data\n",
    "    raw_data = raw_data + org_raw_data\n",
    "    \n",
    "data_preprocessor = BatchPreprocessorLLMSpeakerDescription(tokenizer, dataset_name=dataset_name, window_ct=4, \n",
    "                                            emotion_labels=['happy', 'sad', 'neutral', 'angry', 'excited', 'frustrated'])\n",
    "\n",
    "gr_by_len  = data_preprocessor.preprocess(raw_data)\n",
    "all_data = {}\n",
    "for len_promting, speaker_promts in tqdm(gr_by_len.items()):\n",
    "    for batch_size in [8, 5, 2, 1]:\n",
    "        try:\n",
    "            all_promtings_texts = [e['prompting_input'] for e in speaker_promts]\n",
    "            data_loader = DataLoader(all_promtings_texts, \n",
    "                                batch_size=batch_size, \n",
    "                                shuffle=False)\n",
    "            output_sp_desc = []\n",
    "            with torch.no_grad():\n",
    "                for i, speaker_promts_in_batch in enumerate(data_loader):\n",
    "                    # batch decoded by llm \n",
    "                    inputs = tokenizer(speaker_promts_in_batch, return_tensors=\"pt\", padding=False)\n",
    "                    input_ids = inputs[\"input_ids\"].to(\"cuda\")\n",
    "                    with torch.no_grad():\n",
    "                        outputs = model.generate(input_ids, max_new_tokens=200, temperature=1.0)\n",
    "                    output_text = tokenizer.batch_decode(outputs)\n",
    "                    \n",
    "                    for j, e in enumerate(output_text):\n",
    "                        output_sp_desc.append(e.replace(all_promtings_texts[j], \"\"))\n",
    "            \n",
    "                for i, out in enumerate(output_sp_desc):\n",
    "                    speaker_promts[i]['sp_desc'] = out  \n",
    "            break\n",
    "                    \n",
    "        except Exception as e:\n",
    "            traceback.print_exc()\n",
    "            print(e)\n",
    "            if batch_size == 1:\n",
    "                print([\"Errr \"]*10)\n",
    "                \n",
    "for type_data in ['valid', 'test', 'train']:\n",
    "    data_name_pattern= f'{dataset_name}.{type_data}'\n",
    "    path_processed_data = f'{data_folder}/llm_vectors/{data_name_pattern}_spdesc_{model_name.split(\"/\")[-1]}.json'\n",
    "    \n",
    "    processed_data = {}\n",
    "    if os.path.exists(path_processed_data):\n",
    "        processed_data = json.load(open(path_processed_data, 'rt'))\n",
    "        print(f'- load processed [old] {len(processed_data)} conversations in data-type ={type_data}')\n",
    "        \n",
    "    all_data = {}\n",
    "    for len_promting, speaker_promts in gr_by_len.items():\n",
    "        for description in speaker_promts:\n",
    "            if type_data != description['type_data']:\n",
    "                continue\n",
    "            \n",
    "            if description['conv_id'] not in all_data:\n",
    "                all_data[description['conv_id']] = {\n",
    "                    'all_speaker_names': description['all_speaker_names'],\n",
    "                    'vocab_sp2desc':  {}\n",
    "                }\n",
    "            all_data[description['conv_id']]['vocab_sp2desc'][description['speaker_name']] = description['sp_desc']\n",
    "    \n",
    "    print(f'- sucessful processed [new] {len(all_data)} conversations in data-type ={type_data}')\n",
    "    # json.dump(all_data, open(f'{path_data}_new.json', 'wt'), indent=2)\n",
    "\n",
    "    all_data_new = {}\n",
    "    for k, v in all_data.items():\n",
    "        all_data_new[k] = []\n",
    "        for sp_name in v['all_speaker_names']:\n",
    "            all_data_new[k].append(v['vocab_sp2desc'][sp_name])\n",
    "            \n",
    "    print(f'- update processed [new] {len(all_data_new)} + [old] {len(processed_data)} conversations in data-type ={type_data}')\n",
    "    all_data_new.update(processed_data)\n",
    "    json.dump(all_data_new, open(f'{path_processed_data}', 'wt'), indent=2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/JOBs/tmpdir/pbs.7884080.spcc-adm1/ipykernel_3824609/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">16680716.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">12</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 8&gt;</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'/JOBs/tmpdir/pbs.7884080.spcc-adm1/ipykernel_3824609/16680716.py'</span>                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/phuongnm/per_erc/src/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">main.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">78</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">load_raw_data</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 75 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 76 │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@staticmethod</span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 77 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">load_raw_data</span>(path_data):                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 78 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>raw_data = json.load(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">open</span>(path_data))                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 79 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(raw_data, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">dict</span>):                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 80 │   │   │   </span>new_data_list = []                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 81 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> k, v <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> raw_data.items():                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">FileNotFoundError: </span><span style=\"font-weight: bold\">[</span>Errno <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]</span> No such file or directory: <span style=\"color: #008000; text-decoration-color: #008000\">'../data/all_raw_data//meld.valid.json'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/JOBs/tmpdir/pbs.7884080.spcc-adm1/ipykernel_3824609/\u001b[0m\u001b[1;33m16680716.py\u001b[0m:\u001b[94m12\u001b[0m in \u001b[92m<cell line: 8>\u001b[0m            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'/JOBs/tmpdir/pbs.7884080.spcc-adm1/ipykernel_3824609/16680716.py'\u001b[0m                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/phuongnm/per_erc/src/\u001b[0m\u001b[1;33mmain.py\u001b[0m:\u001b[94m78\u001b[0m in \u001b[92mload_raw_data\u001b[0m                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 75 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 76 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;95m@staticmethod\u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 77 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mload_raw_data\u001b[0m(path_data):                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 78 \u001b[2m│   │   \u001b[0mraw_data = json.load(\u001b[96mopen\u001b[0m(path_data))                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 79 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(raw_data, \u001b[96mdict\u001b[0m):                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 80 \u001b[0m\u001b[2m│   │   │   \u001b[0mnew_data_list = []                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 81 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mfor\u001b[0m k, v \u001b[95min\u001b[0m raw_data.items():                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mFileNotFoundError: \u001b[0m\u001b[1m[\u001b[0mErrno \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m No such file or directory: \u001b[32m'../data/all_raw_data//meld.valid.json'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import json \n",
    "# import os \n",
    "\n",
    "# dataset_name = 'meld'\n",
    "# data_folder = '../data/all_raw_data/'\n",
    "\n",
    "\n",
    "# for type_data in ['valid','train','test']:\n",
    "#     data_name_pattern= f'{dataset_name}.{type_data}'\n",
    "    \n",
    "    \n",
    "#     raw_data = BatchPreprocessor.load_raw_data(f\"{data_folder}/{data_name_pattern}.json\")\n",
    "    \n",
    "#     data_preprocessor = BatchPreprocessorLLMSpeakerDescription(tokenizer, dataset_name=dataset_name, window_ct=4, \n",
    "#                                              emotion_labels=['happy', 'sad', 'neutral', 'angry', 'excited', 'frustrated'])\n",
    "#     all_data = {}\n",
    "#     test_loader = DataLoader(raw_data, \n",
    "#                              batch_size=1, \n",
    "#                              collate_fn=data_preprocessor, \n",
    "#                              shuffle=False)\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         path_data = f'{data_folder}/llm_vectors/{data_name_pattern}_speaker_descriptions.json'\n",
    "#         for i, convs in enumerate(tqdm(test_loader)):\n",
    "#             if os.path.exists(path_data):\n",
    "#                 all_data = json.load(open(path_data, 'rt'))\n",
    "#             for j, conv in enumerate(convs):\n",
    "#                 if conv['s_id'] in all_data:\n",
    "#                     continue\n",
    "#                 speaker_descriptions = []\n",
    "#                 map_speaker2descriptions = {}\n",
    "\n",
    "#                 for speaker_name, prompt_speaker_des_ids in conv['prompts_speaker_description_word_ids'].items():\n",
    "#                     input_ids = prompt_speaker_des_ids.to(\"cuda\") \n",
    "#                     outputs = model.generate(input_ids, max_new_tokens=300)\n",
    "#                     map_speaker2descriptions[speaker_name] = tokenizer.decode(outputs[0])\n",
    "\n",
    "#                 for sp_name in conv['speaker_names']:\n",
    "#                     speaker_descriptions.append(map_speaker2descriptions[sp_name].replace(conv['prompting_input'][sp_name], ''))\n",
    "            \n",
    "#                 all_data[conv['s_id']] = speaker_descriptions\n",
    "#             json.dump(all_data, open(f'{data_folder}/llm_vectors/{data_name_pattern}_speaker_descriptions.json', 'wt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# dataset_name = 'iemocap'\n",
    "# data_folder = '/home/phuongnm/per_erc/data/'\n",
    "\n",
    "\n",
    "# for type_data in [ 'train', 'valid', 'test']:\n",
    "#     data_name_pattern= f'{dataset_name}.{type_data}'\n",
    "    \n",
    "    \n",
    "#     raw_data = BatchPreprocessor.load_raw_data(f\"{data_folder}/{data_name_pattern}.json\")\n",
    "    \n",
    "#     data_preprocessor = BatchPreprocessorLLM(tokenizer, dataset_name=dataset_name, window_ct=4, \n",
    "#                                              emotion_labels=['happy', 'sad', 'neutral', 'angry', 'excited', 'frustrated'])\n",
    "#     all_data = {}\n",
    "    \n",
    "#     test_loader = DataLoader(raw_data, \n",
    "#                              batch_size=1, \n",
    "#                              collate_fn=data_preprocessor, \n",
    "#                              shuffle=False)\n",
    "#     with torch.no_grad():\n",
    "#         for i, conv in enumerate(tqdm(test_loader)):\n",
    "#             llm_vectors = []\n",
    "#             for i_s, sent in enumerate(conv):\n",
    "#                 input_ids = sent['input_ids'].to(\"cuda\")\n",
    "#                 outputs = model(input_ids)\n",
    "#                 sent.pop('input_ids')\n",
    "#                 llm_vectors.append(outputs.last_hidden_state[0][0].cpu())\n",
    "        \n",
    "#             all_data[conv[0]['s_id']] = llm_vectors\n",
    "#     pickle.dump(all_data, open(f'{data_folder}/llm_vectors/{data_name_pattern}_llm_fewshot.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    #  q_input_group_by_len = {}\n",
    "    #     for i_check, support_samples in enumerate(tqdm(all_candidate_examples)):\n",
    "    #         utterances.append(support_samples['q_input'])\n",
    "    #         if i_check not in query_ids:\n",
    "    #             continue\n",
    "    #         str_query, max_new_tokens, num_demonstrations, q_sub_tok_len = self.query_generate_with_support_samples(support_samples, \n",
    "    #                                                                                                                 args.top_k_demos, \n",
    "    #                                                                                                                 50, \n",
    "    #                                                                                                                 missing_predicate[i_check] if missing_predicate is not None else None)\n",
    "    #         if q_sub_tok_len not in q_input_group_by_len:\n",
    "    #             q_input_group_by_len[q_sub_tok_len] = []\n",
    "                \n",
    "    #         q_input_group_by_len[q_sub_tok_len].append([str_query, max_new_tokens, num_demonstrations, q_sub_tok_len, i_check])\n",
    "                    \n",
    "    #     for q_len, gr_info in tqdm(q_input_group_by_len.items()):\n",
    "    #         q_outputs = []\n",
    "            \n",
    "    #         try:\n",
    "    #             # try to infer with llm\n",
    "    #             for batch_info in DataLoader(gr_info, batch_size=args.batch_size, shuffle=False):\n",
    "    #                 batch_queries = batch_info[0]\n",
    "    #                 batch_max_new_tokens = max(batch_info[1])\n",
    "    #                 batch_output =  self.batch_query(batch_queries, batch_max_new_tokens)    # TODO CHECK\n",
    "    #                 q_outputs += batch_output\n",
    "    #         except Exception as e:\n",
    "    #             traceback.print_exc()\n",
    "    #             print(e)\n",
    "    #             continue  # if exception by out of CUDA MEMORY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "c6a2877e1bfde4f5f029020970de5fe9d6d098c79260600128974293316b861d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
